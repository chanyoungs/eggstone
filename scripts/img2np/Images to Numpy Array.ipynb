{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_w = 256\n",
    "img_h = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_nparray(folder_path, error_log_file_name):\n",
    "    file_names = os.listdir(folder_path)\n",
    "    error_logs = \"\"\n",
    "\n",
    "    n = len(file_names)\n",
    "\n",
    "    # Original Dimensions\n",
    "    img_w_original = 400\n",
    "    img_h_original = 400\n",
    "    n_channels = 3\n",
    "    n_classes = 1\n",
    "\n",
    "    # dataset = np.ndarray(shape=((n, n_channels, img_h, img_w)), dtype=np.float32)\n",
    "    dataset_list = []\n",
    "\n",
    "\n",
    "\n",
    "    i, percent, percent_temp, error_index = 0, 0, 0, 0\n",
    "    for file_name in file_names:\n",
    "        img_pil = load_img(os.path.join(folder_path, file_name))\n",
    "        dim = np.array(img_pil).shape\n",
    "    #     print(dim, (img_h_original, img_w_original, n_channels), dim == (img_h_original, img_w_original, n_channels))\n",
    "        if not dim == (img_h_original, img_w_original, n_channels):\n",
    "            error_index += 1\n",
    "            error_logs += f\"\\n{error_index}. {file_name} has dimension {dim}\"\n",
    "            i += 1\n",
    "        else:\n",
    "            img_pil.thumbnail((img_w, img_h))\n",
    "\n",
    "            dataset_list.append(img_to_array(img_pil))\n",
    "\n",
    "            i += 1\n",
    "            percent_temp = 100 * i / n\n",
    "            if percent_temp > percent + 10:\n",
    "                percent += 10\n",
    "                print(f\"{percent}% complete!\")\n",
    "    print(\"100% complete\\n\")\n",
    "\n",
    "    dataset = np.array(dataset_list)\n",
    "    print(f\"Numpy array of images created with dimension: {dataset.shape}\\n\")\n",
    "\n",
    "    if not error_logs == \"\":\n",
    "        f = open(error_log_file_name, \"w\")\n",
    "        f.write(error_logs)\n",
    "        f.close()\n",
    "        print(f\"{error_index} error logs created in {error_log_file_name}\\n\")\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% complete!\n",
      "20% complete!\n",
      "30% complete!\n",
      "40% complete!\n",
      "50% complete!\n",
      "60% complete!\n",
      "70% complete!\n",
      "80% complete!\n",
      "90% complete!\n",
      "100% complete\n",
      "\n",
      "Numpy array of images created with dimension: (2126, 256, 256, 3)\n",
      "\n",
      "43 error logs created in error_logs_good.txt\n",
      "\n",
      "10% complete!\n",
      "20% complete!\n",
      "30% complete!\n",
      "40% complete!\n",
      "50% complete!\n",
      "60% complete!\n",
      "70% complete!\n",
      "80% complete!\n",
      "90% complete!\n",
      "100% complete\n",
      "\n",
      "Numpy array of images created with dimension: (2450, 256, 256, 3)\n",
      "\n",
      "25 error logs created in error_logs_bad.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "good_imgs = images_to_nparray(\"./Images/good/\", \"error_logs_good.txt\")\n",
    "bad_imgs = images_to_nparray(\"./Images/bad/\", \"error_logs_bad.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_x_and_y_train_data(dataset0, dataset1):\n",
    "    if not dataset1[0].shape == dataset1[1].shape:\n",
    "        print(f\"Error: Dimensions of the datasets are inconsistent. {dataset1[0].shape} vs {dataset2[1].shape}\")\n",
    "    else:\n",
    "        n = dataset0.shape[0] + dataset1.shape[0]\n",
    "        \n",
    "        X = np.ndarray(shape=(n, dataset0.shape[1], dataset0.shape[2], dataset0.shape[3]), dtype=np.float32)        \n",
    "        X[:dataset0.shape[0]] = dataset0\n",
    "        X[dataset0.shape[0]:] = dataset1\n",
    "        \n",
    "        y = np.zeros(n)\n",
    "        y[dataset0.shape[0]:] = 1\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_x_and_y_train_data(good_imgs, bad_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"./data/images_{img_w}x{img_h}\", X)\n",
    "np.save(f\"./data/labels_{img_w}x{img_h}\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
